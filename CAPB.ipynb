{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shiwei SU\n",
    "# Takai Lab, Department of Bioengineering, School of Engineering\n",
    "# The University of Tokyo, Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import shap\n",
    "%matplotlib inline\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(input(\"Enter the name of the dataset file: \")+\".csv\")\n",
    "\n",
    "columns_to_drop = [\"ref\", \"Sample\", \"Smiles\"]\n",
    "for column in columns_to_drop:\n",
    "    if column in dataset:\n",
    "        dataset = dataset.drop(column, axis=1)\n",
    "\n",
    "# MaxAbsScaler for descriptors\n",
    "CA = dataset.filter(regex=\"Contact\")\n",
    "df_raw = dataset.drop(\"Contact angle (deg)\", axis = 1)\n",
    "transformer = MaxAbsScaler()\n",
    "df_scaled = transformer.fit_transform(df_raw)\n",
    "dataset_scaled = pd.DataFrame(df_scaled, columns=df_raw.columns)\n",
    "dataset = pd.concat([CA, dataset_scaled], axis = 1)\n",
    "\n",
    "# Distribution\n",
    "y_name = \"Contact Angle\"\n",
    "number_of_bins = 7\n",
    "if dataset.iloc[:, 0].dtype==\"float\":\n",
    "    plt.figure(figsize=(7.5, 3))\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    plt.hist(dataset.iloc[:, 0], bins=number_of_bins, color=\"dodgerblue\")\n",
    "    plt.xlabel(\"Contact Angle\", font=\"Arial\")\n",
    "    plt.ylabel(\"Frequency\", font=\"Arial\")\n",
    "    plt.xticks([0, 30, 60, 90, 120])\n",
    "    plt.yticks([0,5,10,15,20,25,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "param_lasso = {\"alpha\": np.arange(0.05, 3., 0.01),\n",
    "              \"fit_intercept\": [True, False]}\n",
    "\n",
    "param_ridge = {\"alpha\": np.arange(0.05, 3., 0.01),\n",
    "              \"fit_intercept\": [True, False]}\n",
    "\n",
    "param_tree = {\"max_depth\": np.arange(1, 20),\n",
    "             \"min_samples_leaf\": np.arange(1, 10, 1),\n",
    "             \"random_state\": [42]}\n",
    "\n",
    "param_forest = {\"max_depth\": np.arange(1, 20),\n",
    "             \"min_samples_leaf\": np.arange(1, 10, 1),\n",
    "             \"n_estimators\": [50, 100, 200, 300],\n",
    "             \"random_state\": [42]}\n",
    "\n",
    "param_knn = {\"n_neighbors\": np.arange(1, 10),\n",
    "              \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "param_svr = {\"C\": [0.1, 1, 10, 100, 1000],\n",
    "              \"epsilon\": [0.01, 0.1, 1, 10],\n",
    "              \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n",
    "\n",
    "param_mlp = {\"hidden_layer_sizes\": [(50,), (100,), (150,),\n",
    "                                    (50, 50), (100, 100), (150, 150),\n",
    "                                    (50, 100), (50, 150), (100, 150),\n",
    "                                    (50,50,50), (100,100,100), (150, 150, 150),\n",
    "                                    (50, 100, 50), (50, 150, 50), (100, 100, 150), (100, 150, 100)],\n",
    "             \"activation\": [\"relu\", \"logistic\", \"tanh\"],\n",
    "             \"solver\": [\"adam\", \"sgd\"],\n",
    "             \"alpha\": [0.0001, 0.001, 0.01],\n",
    "             \"learning_rate_init\": [0.0001, 0.001, 0.01],\n",
    "             \"shuffle\": [False],\n",
    "             \"max_iter\": [1000]}\n",
    "\n",
    "param_xgb = {\"max_depth\": np.arange(1, 20),\n",
    "             \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "             \"n_estimators\": [50, 100, 150, 250, 500, 1000],\n",
    "             \"random_state\": [42]}\n",
    "\n",
    "models_param = {\n",
    "    \"Lasso\": {\"model\": Lasso(), \"param\": param_lasso},\n",
    "    \"Ridge\": {\"model\": Ridge(), \"param\": param_ridge},\n",
    "    \"Decision Tree\": {\"model\": DecisionTreeRegressor(), \"param\": param_tree},\n",
    "    \"Random Forest\": {\"model\": RandomForestRegressor(), \"param\": param_forest},\n",
    "    \"kNN\": {\"model\": KNeighborsRegressor(), \"param\": param_knn},\n",
    "    \"SVR\": {\"model\": SVR(), \"param\": param_svr},\n",
    "    \"MLP\": {\"model\": MLPRegressor(), \"param\": param_mlp},\n",
    "    \"XGBoost\": {\"model\": XGBRegressor(), \"param\": param_xgb}}\n",
    "\n",
    "optimized_models = {\"Lasso\":{},\n",
    "                    \"Ridge\":{},\n",
    "                    \"Decision Tree\":{},\n",
    "                    \"Random Forest\":{},\n",
    "                    \"kNN\":{},\n",
    "                    \"SVR\":{},\n",
    "                    \"MLP\":{},\n",
    "                    \"XGBoost\":{}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset.drop(\"Contact angle (deg)\", axis = 1))\n",
    "Y = np.array(dataset[\"Contact angle (deg)\"])\n",
    "\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, model_param in models_param.items():\n",
    "    print(\"Training \"+model_name+\"...\")\n",
    "    model = model_param[\"model\"]\n",
    "    param = model_param[\"param\"]\n",
    "    best_para = []\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X):\n",
    "        X_train, y_train = X[train_idx], Y[train_idx]\n",
    "        X_test, y_test = X[test_idx], Y[test_idx]\n",
    "        grid = GridSearchCV(model, param, cv=inner_cv, n_jobs=-1, verbose=1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_para.append(grid.best_params_)\n",
    "        train_scores.append(grid.best_score_)\n",
    "        model = grid.best_estimator_.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2_pred = r2_score(y_test, y_pred)\n",
    "        test_scores.append(r2_pred)\n",
    "    optimized_models[model_name][\"best_para\"] = best_para\n",
    "    optimized_models[model_name][\"train_scores\"] = train_scores\n",
    "    optimized_models[model_name][\"test_scores\"] = test_scores\n",
    "\n",
    "\n",
    "    print(\"-------------------------NEXT-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split validation set\n",
    "train_set, validation_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "#training set\n",
    "X_part = train_set.drop(\"Contact angle (deg)\", axis=1)\n",
    "Y_part = train_set[\"Contact angle (deg)\"].copy()\n",
    "X_part_array = np.array(X_part)\n",
    "Y_part_array = np.array(Y_part)\n",
    "\n",
    "#validation set\n",
    "X_val = validation_set.drop(\"Contact angle (deg)\", axis=1)\n",
    "Y_val = validation_set[\"Contact angle (deg)\"].copy()\n",
    "X_val_array = np.array(X_val)\n",
    "Y_val_array = np.array(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fig(model_name, X_train, Y_train, X_val, Y_val, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions):\n",
    "\n",
    "    model_name = str(model_name)\n",
    "    fig,ax=plt.subplots(figsize=(6, 6))\n",
    "    Axis_line=np.linspace(*ax.get_xlim(),2)\n",
    "    ax.plot(Axis_line,Axis_line,transform=ax.transAxes,linestyle=\"--\",\n",
    "            linewidth=2,color='black',label=\"1:1 Line\")\n",
    "    ax.set_xlim([0,195])\n",
    "    ax.set_ylim([0,195])\n",
    "    \n",
    "    rmse_train_mean = round(np.mean(rmse_train, axis=0), 2)\n",
    "    rmse_val_mean = round(np.mean(rmse_val, axis=0), 2)\n",
    "    rmse_train_std = round(np.std(rmse_train, axis=0), 2)\n",
    "    rmse_val_std = round(np.std(rmse_val, axis=0), 2)\n",
    "    r2_train_mean = round(np.mean(r2_train, axis=0), 2)\n",
    "    r2_val_mean = round(np.mean(r2_val, axis=0), 2)\n",
    "    r2_train_std = round(np.std(r2_train, axis=0), 2)\n",
    "    r2_val_std = round(np.std(r2_val, axis=0), 2)\n",
    "    \n",
    "    scatter1 = ax.scatter(X_train, Y_train, color=\"salmon\", alpha=0.5, label=\"Training set\")\n",
    "    plt1 = ax.errorbar(X_train, Y_train, yerr=std_part_predictions, fmt=\"none\", color=\"r\", alpha=0.5)\n",
    "    scatter2 = ax.scatter(X_val, Y_val, color=\"steelblue\", label=\"Test set\")\n",
    "    plt2 = ax.errorbar(X_val, Y_val, yerr=std_predictions, fmt=\"none\", color=\"b\", alpha=0.5)\n",
    "    plt.legend(handles=[scatter1, scatter2], labels = [\"Training set\", \"Test set\"], loc=\"lower right\", fontsize=14, fancybox=True, markerscale=0.8, framealpha=0.8, handlelength=0.5)\n",
    "\n",
    "    ax.text(5, 190, \" Score of \"+model_name+\" \"\n",
    "            \"\\n $RMSE$ (training): \"+str(rmse_train_mean)+\" ± \"+str(rmse_train_std)+\" \"\n",
    "            \"\\n $RMSE$ (test): \"+str(rmse_val_mean)+\" ± \"+str(rmse_val_std)+\" \"\n",
    "            \"\\n $R\\u00b2$ (training): \"+str(r2_train_mean)+\" ± \"+str(r2_train_std)+\" \"\n",
    "            \"\\n $R\\u00b2$ (test): \"+str(r2_val_mean)+\" ± \"+str(r2_val_std)+\" \",\n",
    "            verticalalignment='top', horizontalalignment='left',fontsize=16,\n",
    "            bbox={'facecolor': 'lightskyblue', 'alpha': 0.2, 'pad': 1})\n",
    "\n",
    "    plt.xlabel(\"Reported CA \", fontsize=20, fontweight=\"bold\", font=\"Arial\")\n",
    "    plt.ylabel(\"Predicted CA\", fontsize=20, fontweight=\"bold\", font=\"Arial\")\n",
    "    new_ticks = np.linspace(0, 180, 7)\n",
    "    plt.xticks(new_ticks, fontweight=\"bold\")\n",
    "    plt.yticks(new_ticks, fontweight=\"bold\")\n",
    "    ax.tick_params(labelsize=\"16\", direction=\"in\")\n",
    "\n",
    "    plt.rcParams[\"axes.titley\"] = 1.03\n",
    "    plt.title(model_name, fontsize=26,fontweight=\"bold\",font=\"Arial\", color=\"black\")\n",
    "            \n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_lasso(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = Lasso(**optimized_models[\"Lasso\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))       \n",
    "\n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    \n",
    "result_lasso(optimized_models, \"Lasso\", X_part_array, Y_part_array, X_val_array, Y_val_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_ridge(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = Ridge(**optimized_models[\"Ridge\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))     \n",
    "        \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    \n",
    "result_ridge(optimized_models, \"Ridge\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_tree(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = DecisionTreeRegressor(**optimized_models[\"Decision Tree\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))   \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "    \n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    \n",
    "result_tree(optimized_models, \"Decision Tree\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_forest(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = RandomForestRegressor(**optimized_models[\"Random Forest\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))   \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    \n",
    "result_forest(optimized_models, \"Random Forest\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_knn(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = KNeighborsRegressor(**optimized_models[\"kNN\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))   \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "\n",
    "result_knn(optimized_models, \"kNN\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_svr(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = SVR(**optimized_models[\"SVR\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))   \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    return model\n",
    "    \n",
    "svr = result_svr(optimized_models, \"SVR\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_mlp(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = MLPRegressor(**optimized_models[\"MLP\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))   \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    \n",
    "result_mlp(optimized_models, \"MLP\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_xgb(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    all_y_predictions = []\n",
    "    all_y_part_predictions = []\n",
    "    rmse_train = []\n",
    "    rmse_val = []\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    for i in range(5):\n",
    "        model = XGBRegressor(**optimized_models[\"XGBoost\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        y_part_pred = model.predict(X_part_array)\n",
    "        y_pred = model.predict(X_val_array)\n",
    "        all_y_part_predictions.append(y_part_pred)\n",
    "        all_y_predictions.append(y_pred)\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(Y_part_array, y_part_pred)))\n",
    "        rmse_val.append(np.sqrt(mean_squared_error(Y_val_array, y_pred)))\n",
    "        r2_train.append(r2_score(Y_part_array, y_part_pred))\n",
    "        r2_val.append(r2_score(Y_val_array, y_pred))   \n",
    "    mean_part_predictions = np.mean(all_y_part_predictions, axis=0)\n",
    "    std_part_predictions = np.std(all_y_part_predictions, axis=0)\n",
    "    mean_predictions = np.mean(all_y_predictions, axis=0)\n",
    "    std_predictions = np.std(all_y_predictions, axis=0)\n",
    "    gen_fig(model_name, Y_part_array, mean_part_predictions, Y_val_array, mean_predictions, rmse_train, rmse_val, r2_train, r2_val, std_part_predictions, std_predictions)\n",
    "    return model\n",
    "    \n",
    "xgb_model = result_xgb(optimized_models, \"XGBoost\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_svr(optimized_models, model_name, X_part_array, Y_part_array, X_val_array, Y_val_array):\n",
    "    for i in range(5):\n",
    "        model = SVR(**optimized_models[\"SVR\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        explainer = shap.KernelExplainer(model.predict, X_part_array)\n",
    "        shap_values = explainer.shap_values(X_val_array)\n",
    "        shap.summary_plot(shap_values, X_val_array, feature_names=X_part.columns.values, plot_size=(8,5), color_bar_label=\"Feature SHAP Value\", auto_size_plot=None)\n",
    "        plt.show()\n",
    "    \n",
    "shap_svr(optimized_models, \"SVR\", X_part_array, Y_part_array, X_val_array, Y_val_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_forest(optimized_models, X_part_array, Y_part_array, X_val_array):\n",
    "    for i in range(5):\n",
    "        model = RandomForestRegressor(**optimized_models[\"Random Forest\"][\"best_para\"][i])\n",
    "        model.fit(X_part_array, Y_part_array)\n",
    "        explainer = shap.KernelExplainer(model.predict, X_part_array)\n",
    "        shap_values = explainer.shap_values(X_val_array)\n",
    "        shap.summary_plot(shap_values, X_val_array, feature_names=X_part.columns.values, plot_size=(8,5), color_bar_label=\"Feature SHAP Value\", auto_size_plot=None)\n",
    "        plt.show()\n",
    "    \n",
    "shap_forest(optimized_models, X_part_array, Y_part_array, X_val_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_xgb(optimized_models, X_part, Y_part, X_val):\n",
    "    for i in range(5):\n",
    "        model = XGBRegressor(**optimized_models[\"XGBoost\"][\"best_para\"][i])\n",
    "        model.fit(X_part, Y_part)\n",
    "        explainer = shap.KernelExplainer(model.predict, X_part)\n",
    "        shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "        shap.summary_plot(shap_values, X_val, feature_names=X_part.columns.values, plot_size=(8,5), color_bar_label=\"Feature SHAP Value\", auto_size_plot=None)\n",
    "        plt.show()\n",
    "        \n",
    "shap_xgb(optimized_models, X_part, Y_part, X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fb78bbd6fc5705804677535441b2a061b8a22456f5f1d3f446cd9a69f724dba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

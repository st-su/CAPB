{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shiwei SU\n",
    "# Takai Lab, Department of Bioengineering, School of Engineering\n",
    "# The University of Tokyo, Japan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Accuracy vs Data Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(input(\"Enter the name of the dataset file: \")+\".csv\")\n",
    "\n",
    "columns_to_drop = [\"ref\", \"Sample\", \"Smiles\"]\n",
    "for column in columns_to_drop:\n",
    "    if column in dataset:\n",
    "        dataset = dataset.drop(column, axis=1)\n",
    "\n",
    "# MaxAbsScaler for descriptors\n",
    "CA = dataset.filter(regex=\"Contact\")\n",
    "df_raw = dataset.drop(\"Contact angle (deg)\", axis = 1)\n",
    "transformer = MaxAbsScaler()\n",
    "df_scaled = transformer.fit_transform(df_raw)\n",
    "dataset_scaled = pd.DataFrame(df_scaled, columns=df_raw.columns)\n",
    "dataset = pd.concat([CA, dataset_scaled], axis = 1)\n",
    "\n",
    "# Distribution\n",
    "y_name = \"Contact Angle\"\n",
    "number_of_bins = 7\n",
    "if dataset.iloc[:, 0].dtype==\"float\":\n",
    "    plt.figure(figsize=(7.5, 3))\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    plt.hist(dataset.iloc[:, 0], bins=number_of_bins, color=\"dodgerblue\")\n",
    "    plt.xlabel(\"Contact Angle\", font=\"Arial\")\n",
    "    plt.ylabel(\"Frequency\", font=\"Arial\")\n",
    "    plt.xticks([0, 30, 60, 90, 120])\n",
    "    plt.yticks([0,5,10,15,20,25,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset.drop(\"Contact angle (deg)\", axis = 1))\n",
    "Y = np.array(dataset[\"Contact angle (deg)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "param_lasso = {\"alpha\": np.arange(0.05, 3., 0.01),\n",
    "              \"fit_intercept\": [True, False]}\n",
    "\n",
    "param_ridge = {\"alpha\": np.arange(0.05, 3., 0.01),\n",
    "              \"fit_intercept\": [True, False]}\n",
    "\n",
    "param_tree = {\"max_depth\": np.arange(1, 20),\n",
    "             \"min_samples_leaf\": np.arange(1, 10, 1),\n",
    "             \"random_state\": [42]}\n",
    "\n",
    "param_forest = {\"max_depth\": np.arange(1, 20),\n",
    "             \"min_samples_leaf\": np.arange(1, 10, 1),\n",
    "             \"n_estimators\": [50, 100, 200, 300],\n",
    "             \"random_state\": [42]}\n",
    "\n",
    "param_knn = {\"n_neighbors\": np.arange(1, 10),\n",
    "              \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "param_svr = {\"C\": [0.1, 1, 10, 100, 1000],\n",
    "              \"epsilon\": [0.01, 0.1, 1, 10],\n",
    "              \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n",
    "\n",
    "param_mlp = {\"hidden_layer_sizes\": [(50,), (100,), (150,),\n",
    "                                    (50, 50), (100, 100), (150, 150),\n",
    "                                    (50, 100), (50, 150), (100, 150),\n",
    "                                    (50,50,50), (100,100,100), (150, 150, 150),\n",
    "                                    (50, 100, 50), (50, 150, 50), (100, 100, 150), (100, 150, 100)],\n",
    "             \"activation\": [\"relu\", \"logistic\", \"tanh\"],\n",
    "             \"solver\": [\"adam\", \"sgd\"],\n",
    "             \"alpha\": [0.0001, 0.001, 0.01],\n",
    "             \"learning_rate_init\": [0.0001, 0.001, 0.01],\n",
    "             \"shuffle\": [False],\n",
    "             \"max_iter\": [1000]}\n",
    "\n",
    "param_xgb = {\"max_depth\": np.arange(1, 20),\n",
    "             \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "             \"n_estimators\": [50, 100, 150, 250, 500, 1000],\n",
    "             \"random_state\": [42]}\n",
    "\n",
    "models_param = {\n",
    "    \"Lasso\": {\"model\": Lasso(), \"param\": param_lasso},\n",
    "    \"Ridge\": {\"model\": Ridge(), \"param\": param_ridge},\n",
    "    \"Linear Regression\": {\"model\": LinearRegression(), \"param\": param_linear},\n",
    "    \"Decision Tree\": {\"model\": DecisionTreeRegressor(), \"param\": param_tree},\n",
    "    \"Random Forest\": {\"model\": RandomForestRegressor(), \"param\": param_forest},\n",
    "    \"kNN\": {\"model\": KNeighborsRegressor(), \"param\": param_knn},\n",
    "    \"SVR\": {\"model\": SVR(), \"param\": param_svr},\n",
    "    \"MLP\": {\"model\": MLPRegressor(), \"param\": param_mlp},\n",
    "    \"XGBoost\": {\"model\": XGBRegressor(), \"param\": param_xgb}\n",
    "}\n",
    "\n",
    "optimized_models = {\"Lasso\":{},\n",
    "                    \"Ridge\":{},\n",
    "                    \"Linear Regression\":{},\n",
    "                    \"Decision Tree\":{},\n",
    "                    \"Random Forest\":{},\n",
    "                    \"kNN\":{},\n",
    "                    \"SVR\":{},\n",
    "                    \"MLP\":{},\n",
    "                    \"XGBoost\":{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_splits = 5\n",
    "outer_splits = 20\n",
    "inner = KFold(n_splits=inner_splits, shuffle=True, random_state=42)\n",
    "outer = KFold(n_splits=outer_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "block_size = len(X) // outer_splits\n",
    "data_split = {}\n",
    "\n",
    "for k, (train_idx, test_idx) in tqdm(enumerate(outer.split(X))):\n",
    "    for i in range(outer_splits-1):\n",
    "        training_size = (i + 1) * block_size\n",
    "        train_indices = train_idx[: training_size]\n",
    "        X_train, X_test = X[train_indices], X[test_idx]\n",
    "        Y_train, Y_test = Y[train_indices], Y[test_idx]\n",
    "        dict_key1 = f\"training_size_{training_size}\"\n",
    "        dict_key2 = f\"outer_cv_no_{k + 1}\"\n",
    "        if dict_key1 not in data_split:\n",
    "            data_split[dict_key1] = {}\n",
    "        data_split[dict_key1][dict_key2] = ((X_train, Y_train), (X_test, Y_test))\n",
    "\n",
    "# Nested CV\n",
    "for model_name, model_param in models_param.items():\n",
    "    print(\"Training \" + model_name + \"...\")\n",
    "    model = model_param[\"model\"]\n",
    "    param = model_param[\"param\"]\n",
    "    test_scores_vs_training_size = []\n",
    "    for k in range(outer_splits-1):\n",
    "        training_size = (k + 1) * block_size\n",
    "        data_key1 = f\"training_size_{training_size}\"\n",
    "        optimized_models[model_name][data_key1] = {}\n",
    "        print(f\"best parameter for training_size={training_size}\")\n",
    "        best_para = []\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        for i in range(outer_splits - 1):\n",
    "            print(str(data_key1))\n",
    "            data_key2 = f\"outer_cv_no_{i + 1}\"\n",
    "            print(data_key2)\n",
    "            (X_train, y_train), (X_test, y_test) = data_split[data_key1][data_key2]\n",
    "            grid = GridSearchCV(model, param, cv=inner, n_jobs=-1, verbose=0)\n",
    "            grid.fit(X_train, y_train)\n",
    "            best_para.append(grid.best_params_)\n",
    "            train_scores.append(grid.best_score_)\n",
    "            model = grid.best_estimator_.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            r2_pred = r2_score(y_test, y_pred)\n",
    "            test_scores.append(r2_pred)\n",
    "        test_scores_mean = mean(test_scores)\n",
    "        test_scores_vs_training_size.append(test_scores_mean)\n",
    "    optimized_models[model_name][\"test_scores\"] = test_scores_vs_training_size\n",
    "    print(\"-------------------------NEXT-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_score = optimized_models[\"Lasso\"][\"test_scores\"]\n",
    "ridge_score = optimized_models[\"Ridge\"][\"test_scores\"]\n",
    "linear_score = optimized_models[\"Linear Regression\"][\"test_scores\"]\n",
    "tree_score = optimized_models[\"Decision Tree\"][\"test_scores\"]\n",
    "forest_score = optimized_models[\"Random Forest\"][\"test_scores\"]\n",
    "knn_score = optimized_models[\"kNN\"][\"test_scores\"]\n",
    "svr_score = optimized_models[\"SVR\"][\"test_scores\"]\n",
    "mlp_score = optimized_models[\"MLP\"][\"test_scores\"]\n",
    "xgb_score = optimized_models[\"XGBoost\"][\"test_scores\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [lasso_score, ridge_score, linear_score, tree_score, forest_score, knn_score, svr_score, mlp_score xgb_score]\n",
    "for score in scores:\n",
    "    fig,ax=plt.subplots(figsize=(6, 3))\n",
    "    x = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "    score = score[:16]\n",
    "    y = [max(0, value) for value in score]\n",
    "    plt.plot(x, y, linestyle=\"-\")\n",
    "    ax.set_xlim([0,85])\n",
    "    ax.set_ylim([-0.05,1.05])\n",
    "    x_ticks = np.linspace(0, 80, 9)\n",
    "    plt.xticks(x_ticks, fontweight=\"bold\")\n",
    "    y_ticks = np.linspace(0, 1, 6)\n",
    "    plt.yticks(y_ticks, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Data Size for Training Set\", fontsize=20, fontweight=\"bold\", font=\"Arial\")\n",
    "    plt.ylabel(\"$R\\u00b2$ Score\", fontsize=20, fontweight='bold', font=\"Arial\")\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "x = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n",
    "y_lasso = [max(0, value) for value in lasso_score[:]]\n",
    "y_ridge = [max(0, value) for value in ridge_score[:]]\n",
    "y_linear = [max(0, value) for value in linear_score[:]]\n",
    "y_tree = [max(0, value) for value in tree_score[:]]\n",
    "y_forest = [max(0, value) for value in forest_score[:]]\n",
    "y_knn = [max(0, value) for value in knn_score[:]]\n",
    "y_svr = [max(0, value) for value in svr_score[:]]\n",
    "y_mlp = [max(0, value) for value in mlp_score[:]]\n",
    "y_xgb = [max(0, value) for value in xgb_score[:]]\n",
    "plt.plot(x, y_lasso, label=\"Lasso\", linestyle=\"-\")\n",
    "plt.plot(x, y_ridge, label=\"Ridge\", linestyle=\"-\")\n",
    "plt.plot(x, y_linear, label=\"Linear Regression\", linestyle=\"-\")\n",
    "plt.plot(x, y_tree, label=\"Decision Tree\", linestyle=\"-\")\n",
    "plt.plot(x, y_forest, label=\"Random Forest\", linestyle=\"-\")\n",
    "plt.plot(x, y_knn, label=\"kNN\", linestyle=\"-\")\n",
    "plt.plot(x, y_svr, label=\"SVR\", linestyle=\"-\")\n",
    "plt.plot(x, y_mlp, label=\"MLP\", linestyle=\"-\")\n",
    "plt.plot(x, y_xgb, label=\"XGBoost\", linestyle=\"-\")\n",
    "ax.set_xlim([0,100])\n",
    "ax.set_ylim([-0.05,1.05])\n",
    "x_ticks = np.linspace(0, 100,11)\n",
    "plt.xticks(x_ticks, fontweight=\"bold\")\n",
    "y_ticks = np.linspace(0, 1, 6)\n",
    "plt.yticks(y_ticks, fontweight=\"bold\")\n",
    "plt.xlabel(\"Data Size for Training Set\", fontsize=20, fontweight=\"bold\", font=\"Arial\")\n",
    "plt.ylabel(\"$R\\u00b2$ Score\", fontsize=20, fontweight=\"bold\", font=\"Arial\")\n",
    "plt.legend(loc=\"upper left\", fontsize=10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fb78bbd6fc5705804677535441b2a061b8a22456f5f1d3f446cd9a69f724dba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
